#!/bin/bash
# å¿«é€Ÿæµ‹è¯•è„šæœ¬ï¼šåªæŠ“å–å‰ 10 ä¸ª RSS æº

cd "$(dirname "$0")"

echo "ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šåªæŠ“å–å‰ 10 ä¸ª RSS æº"
echo ""

python3 << 'PYTHON_EOF'
from generate_rss_report import parse_opml, fetch_all_feeds, filter_yesterday_articles, prepare_articles_json
import json

# 1. è§£æ OPML
opml_path = '/Users/donghan/Downloads/BestBlogs_RSS_ALL.opml'
feeds = parse_opml(opml_path)
print(f"âœ… è§£æ OPML: æ‰¾åˆ° {len(feeds)} ä¸ªæº\n")

# 2. åªæŠ“å–å‰ 10 ä¸ªæº
test_feeds = feeds[:10]
print(f"ğŸŒ æŠ“å–å‰ {len(test_feeds)} ä¸ªæºè¿›è¡Œæµ‹è¯•...\n")
results = fetch_all_feeds(test_feeds, max_workers=5)

# 3. è¿‡æ»¤æ˜¨æ—¥å†…å®¹
filtered, start_date, end_date = filter_yesterday_articles(results, days_back=1)
print(f"\nâœ… è¿‡æ»¤å®Œæˆ:")
print(f"   æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d %H:%M')} - {end_date.strftime('%Y-%m-%d %H:%M')}")
print(f"   æ˜¨æ—¥æ–‡ç« : {len(filtered)} ç¯‡\n")

# 4. å‡†å¤‡æ•°æ®å¹¶ä¿å­˜
if len(filtered) > 0:
    data = prepare_articles_json(filtered, start_date, end_date)
    
    # ä¿å­˜ä¸º JSON
    output_file = f"test_rss_articles_{start_date.strftime('%Y%m%d')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   æ€»æ–‡ç« æ•°: {data['meta']['total_articles']}")
    print(f"   æ¥æºæ•°é‡: {data['meta']['total_sources']}")
    print(f"   å·²ä¿å­˜åˆ°: {output_file}\n")
    
    print(f"ğŸ“ å‰ 5 ç¯‡æ–‡ç« :")
    for i, article in enumerate(data['articles'][:5], 1):
        print(f"   {i}. {article['title'][:60]}...")
        print(f"      æ¥æº: {article['source']} | æ—¶é—´: {article['time']}")
        print(f"      é“¾æ¥: {article['link'][:80]}...")
        print()
else:
    print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ˜¨æ—¥æ–‡ç« ï¼Œå°è¯•æ‰©å¤§æ—¶é—´èŒƒå›´ï¼š")
    print("   python3 generate_rss_report.py 3")

print("âœ… æµ‹è¯•å®Œæˆï¼")
PYTHON_EOF
